# SignLanguage_hackathonProject

# We are Team Alpha consisting of 
  1: Vyoma Desai 
  2: Zakaria Muhammad
  
# Video Link 
https://www.youtube.com/watch?v=25SaNF6o-M0
https://www.youtube.com/watch?v=bqsxQMrI0Wo


# Presentation Link 
https://docs.google.com/presentation/d/1oJGdMRia-bbe-qVaSqtb3BY4Qwbb-v9RSH824NdwCpU/edit#slide=id.g12491bf40ca_0_5


# Introduction 
Sign languages have developed as useful means of communication, its like a bread and butter for Deaf ,Dumb and blind people. There were 2800 graduates in 2020 who were awarded American Sign Language (ASL)  degrees.

It is a natural language that serves as the predominant sign language of Deaf communities in the United States.

It's also the best way to develop awareness and sensitivity to the Deaf culture, a community of non-hearing individuals which number more than 1 million in the United States alone.

# PROBLEM STATEMENT AND SOLUTION
Every day we see many people who are facing illness like deaf, dumb and blind etc. They face difficulty to interact with others.

Aim of our project is to develop a concept of virtual talking system without sensor for people who are in need, this concept is achieved by using CNN-based machine learning image processing and human hand gesture input. This mainly helps people who canâ€™t talk with other people and for normal people who cannot understand their language.

Our solution is also focused on converting such sign gestures into speech that can be understood by person with vision impairment and normal people.

BENEFITS OF ASL :
ASL helps communicate better and sooner and leads to higher reading levels in kids, adults and senior citizens by bringing 
cognitive (judgement based) benefits.

# Future Work
We used a compact CNN-based architecture and our model is capable of predicting gestures from American sign language in real-time with high efficiency. 

These predicted alphabets are converted to form words and hence form sentences. These sentences are converted into voice modules by incorporating Google Text to Speech (gTTS API).

Implementation of high quality fast action-based videos from Text to Sign language is part of future work.


